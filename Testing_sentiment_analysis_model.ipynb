{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCM0bZRb8UZ8C822jaR194",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rupsha-Chatterjee/msc_final_project/blob/main/Testing_sentiment_analysis_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing the LSTM model**"
      ],
      "metadata": {
        "id": "P9KIOsyaZPLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
        "\n",
        "# Load the model\n",
        "model = load_model(r\"model.h5\")\n",
        "\n",
        "# Load the tokenizer from a JSON file\n",
        "with open(r\"tokenizer.json\", 'r') as f:\n",
        "    tokenizer_json = json.load(f)\n",
        "    tokenizer = tokenizer_from_json(tokenizer_json)\n",
        "\n",
        "# Define the input text\n",
        "text = 'i felt anger when at the end of a telephone call'\n",
        "\n",
        "# Define the sentiment labels and their corresponding emojis\n",
        "labels_dict = {\n",
        "    0: 'sadness',\n",
        "    1: 'joy',\n",
        "    2: 'love',\n",
        "    3: 'anger',\n",
        "    4: 'fear',\n",
        "    5: 'surprise'\n",
        "}\n",
        "\n",
        "emojis_dict = {\n",
        "    0: 'üò¢',  # sadness\n",
        "    1: 'üòä',  # joy\n",
        "    2: '‚ù§Ô∏è',  # love\n",
        "    3: 'üò†',  # anger\n",
        "    4: 'üò®',  # fear\n",
        "    5: 'üò≤'   # surprise\n",
        "}\n",
        "\n",
        "# Convert text into a list containing a single string\n",
        "texts = [text]\n",
        "\n",
        "# Tokenize the text using the loaded tokenizer\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "# Pad sequences to ensure they all have the same length\n",
        "max_sequence_length = 66  # Assuming a maximum sequence length\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "\n",
        "# Use model.predict() with the padded sequences\n",
        "y = model.predict(padded_sequences)\n",
        "\n",
        "# Assuming y is an array of probabilities\n",
        "# Assuming you want to get the label corresponding to the highest probability\n",
        "predicted_label_index = np.argmax(y)\n",
        "\n",
        "# Retrieve the corresponding label from the labels dictionary\n",
        "predicted_label = labels_dict.get(predicted_label_index)\n",
        "predicted_emoji = emojis_dict.get(predicted_label_index)\n",
        "\n",
        "# Print the predicted sentiment and its corresponding emoji\n",
        "print(f\"Predicted Sentiment: {predicted_label}\")\n",
        "print(f\"Emoji: {predicted_emoji}\")\n"
      ],
      "metadata": {
        "id": "oxPgmkD34aTV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4ecdc8b-427d-45fa-be31-aee2a4171cb4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 908ms/step\n",
            "Predicted Sentiment: anger\n",
            "Emoji: üò†\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import tokenizer_from_json\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Load the model\n",
        "model = load_model(r\"model.h5\")\n",
        "\n",
        "# Load the tokenizer from a JSON file\n",
        "with open(r\"tokenizer.json\", 'r') as f:\n",
        "    tokenizer_json = json.load(f)\n",
        "    tokenizer = tokenizer_from_json(tokenizer_json)\n",
        "\n",
        "# Define the sentiment labels and their corresponding emojis\n",
        "labels_dict = {\n",
        "    0: 'sadness',\n",
        "    1: 'joy',\n",
        "    2: 'love',\n",
        "    3: 'anger',\n",
        "    4: 'fear',\n",
        "    5: 'surprise'\n",
        "}\n",
        "\n",
        "emojis_dict = {\n",
        "    0: 'üò¢',  # sadness\n",
        "    1: 'üòä',  # joy\n",
        "    2: '‚ù§Ô∏è',  # love\n",
        "    3: 'üò†',  # anger\n",
        "    4: 'üò®',  # fear\n",
        "    5: 'üò≤'   # surprise\n",
        "}\n",
        "\n",
        "def predict_sentiments(texts):\n",
        "    results = []\n",
        "\n",
        "    # Tokenize the text using the loaded tokenizer\n",
        "    sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "    # Pad sequences to ensure they all have the same length\n",
        "    max_sequence_length = 66  # Assuming a maximum sequence length\n",
        "    padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "\n",
        "    # Use model.predict() with the padded sequences\n",
        "    y = model.predict(padded_sequences)\n",
        "\n",
        "    # Process each prediction\n",
        "    for i in range(len(y)):\n",
        "        predicted_label_index = np.argmax(y[i])\n",
        "        predicted_label = labels_dict.get(predicted_label_index)\n",
        "        predicted_emoji = emojis_dict.get(predicted_label_index)\n",
        "        results.append((texts[i], predicted_label, predicted_emoji))\n",
        "\n",
        "    return results\n",
        "\n",
        "# Example usage with a dataset:\n",
        "data = [\n",
        "    'i felt anger when at the end of a telephone call',\n",
        "    'i feel gorgeous yes',\n",
        "    'i felt loved when my friend called to check on me'\n",
        "]\n",
        "\n",
        "predictions = predict_sentiments(data)\n",
        "\n",
        "# Convert the results to a DataFrame for better visualization\n",
        "df = pd.DataFrame(predictions, columns=['Text', 'Predicted Sentiment', 'Emoji'])\n",
        "\n",
        "# Print the results in a table format\n",
        "print(tabulate(df, headers='keys', tablefmt='grid'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLc6WAfctlAm",
        "outputId": "556d4e14-4adc-4444-f407-db72ba542d87"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 928ms/step\n",
            "+----+---------------------------------------------------+-----------------------+---------+\n",
            "|    | Text                                              | Predicted Sentiment   | Emoji   |\n",
            "+====+===================================================+=======================+=========+\n",
            "|  0 | i felt anger when at the end of a telephone call  | anger                 | üò†      |\n",
            "+----+---------------------------------------------------+-----------------------+---------+\n",
            "|  1 | i feel gorgeous yes                               | joy                   | üòä      |\n",
            "+----+---------------------------------------------------+-----------------------+---------+\n",
            "|  2 | i felt loved when my friend called to check on me | love                  | ‚ù§Ô∏è      |\n",
            "+----+---------------------------------------------------+-----------------------+---------+\n"
          ]
        }
      ]
    }
  ]
}